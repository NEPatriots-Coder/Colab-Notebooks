{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1wcmshf3eXQ5dfIcgJVMUdssMnHFaZhjD",
      "authorship_tag": "ABX9TyNQx3hEPsR/M4Tc2lG+PvXW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NEPatriots-Coder/Colab-Notebooks/blob/main/Copy_of_InsuranceAssesment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZ35fSvKlPWD",
        "outputId": "e710a487-3d1c-477b-9dec-0017852f9714"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "fB7nKbQ6lS6Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the Kaggle Medical Cost Personal Dataset for risk analysis\n",
        "# Dataset columns: age, sex, bmi, children, smoker, region, charges\n",
        "\n",
        "def prepared_data(insurance_data):\n",
        "  df = insurance_data.copy()\n",
        "\n",
        "  charge_threshold = df['charges'].quantile(0.75)\n",
        "  df['risk_level'] = (df['charges'] > charge_threshold).astype(int)\n",
        "\n",
        "\n",
        "\n",
        "  return df\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ioVhsToRlp9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EnhancedInsuranceRiskScorer:\n",
        "    def __init__(self):\n",
        "        self.model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "        self.scaler = StandardScaler()\n",
        "        self.feature_columns = None\n",
        "\n",
        "    def preprocess_data(self, data):\n",
        "        \"\"\"Preprocess insurance data from Kaggle dataset for risk scoring.\"\"\"\n",
        "        # Convert categorical variables to numeric\n",
        "        data['sex'] = data['sex'].map({'male': 0, 'female': 1})\n",
        "        data['smoker'] = data['smoker'].map({'no': 0, 'yes': 1})\n",
        "\n",
        "        # Create age groups and BMI categories for risk factors\n",
        "        data['age_group'] = pd.cut(data['age'], bins=[0, 25, 35, 50, 65, 100],\n",
        "                                 labels=['0-25', '26-35', '36-50', '51-65', '65+'])\n",
        "        data['bmi_category'] = pd.cut(data['bmi'], bins=[0, 18.5, 25, 30, 100],\n",
        "                                    labels=['underweight', 'normal', 'overweight', 'obese'])\n",
        "\n",
        "        # One-hot encode categorical variables\n",
        "        data = pd.get_dummies(data, columns=['age_group', 'bmi_category', 'region'])\n",
        "\n",
        "        if self.feature_columns is None:\n",
        "            # Store feature columns during training\n",
        "            self.feature_columns = [col for col in data.columns\n",
        "                                  if col not in ['charges', 'risk_level']]\n",
        "\n",
        "        return data\n",
        "\n",
        "    def train(self, data):\n",
        "        \"\"\"Train the risk scoring model.\"\"\"\n",
        "        # Preprocess the data\n",
        "        processed_data = self.preprocess_data(data)\n",
        "\n",
        "        # Define features and target\n",
        "        features = processed_data[self.feature_columns]\n",
        "        target = processed_data['risk_level']\n",
        "\n",
        "        # Scale the features\n",
        "        self.scaler.fit(features)\n",
        "        X_scaled = self.scaler.transform(features)\n",
        "\n",
        "        # Split the data and train the model\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X_scaled, target,\n",
        "                                                          test_size=0.2,\n",
        "                                                          random_state=42)\n",
        "        self.model.fit(X_train, y_train)\n",
        "\n",
        "        # Calculate and print model performance metrics\n",
        "        train_accuracy = self.model.score(X_train, y_train)\n",
        "        test_accuracy = self.model.score(X_test, y_test)\n",
        "\n",
        "        print(\"\\nModel Performance Metrics:\")\n",
        "        print(f\"Training Accuracy: {train_accuracy:.2f}\")\n",
        "        print(f\"Testing Accuracy: {test_accuracy:.2f}\")\n",
        "\n",
        "        # Print feature importance analysis\n",
        "        self.analyze_feature_importance()\n",
        "\n",
        "        return test_accuracy\n",
        "\n",
        "    def predict_risk(self, new_data):\n",
        "        \"\"\"Predict risk levels for new insurance applications.\"\"\"\n",
        "        # Preprocess new data\n",
        "        processed_data = self.preprocess_data(new_data)\n",
        "\n",
        "        # Ensure all feature columns exist\n",
        "        for col in self.feature_columns:\n",
        "            if col not in processed_data.columns:\n",
        "                processed_data[col] = 0\n",
        "\n",
        "        # Select and order features\n",
        "        features = processed_data[self.feature_columns]\n",
        "\n",
        "        # Scale features and predict\n",
        "        X_scaled = self.scaler.transform(features)\n",
        "        risk_predictions = self.model.predict(X_scaled)\n",
        "        risk_probabilities = self.model.predict_proba(X_scaled)\n",
        "\n",
        "        return risk_predictions, risk_probabilities\n",
        "\n",
        "    def analyze_feature_importance(self):\n",
        "        \"\"\"Analyze and display the importance of each feature in risk prediction.\"\"\"\n",
        "        feature_importance = pd.DataFrame({\n",
        "            'feature': self.feature_columns,\n",
        "            'importance': self.model.feature_importances_\n",
        "        })\n",
        "        feature_importance = feature_importance.sort_values('importance',\n",
        "                                                          ascending=False)\n",
        "\n",
        "        print(\"\\nTop 10 Most Important Risk Factors:\")\n",
        "        print(feature_importance.head(10))\n",
        "\n",
        "        return feature_importance"
      ],
      "metadata": {
        "id": "MWHNAP82gnOO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "\n",
        "    insurance_data = pd.read_csv(\"/content/drive/MyDrive/DataCSV's/insurance.csv\")\n",
        "\n",
        "    # Prepare the data\n",
        "    prepared_data = prepare_data(insurance_data)\n",
        "\n",
        "    # Initialize and train the model\n",
        "    risk_scorer = EnhancedInsuranceRiskScorer()\n",
        "    risk_scorer.train(prepared_data)\n",
        "\n",
        "    # Example: Make predictions for new applications\n",
        "    new_applications = pd.DataFrame({\n",
        "        'age': [30, 50],\n",
        "        'sex': ['female', 'male'],\n",
        "        'bmi': [23.5, 29.8],\n",
        "        'children': [1, 2],\n",
        "        'smoker': ['no', 'yes'],\n",
        "        'region': ['southwest', 'northeast'],\n",
        "        'charges': [0, 0]  # Charges would be unknown for new applications\n",
        "    })\n",
        "\n",
        "    predictions, probabilities = risk_scorer.predict_risk(new_applications)\n",
        "\n",
        "    print(\"\\nRisk Predictions for New Applications:\")\n",
        "    for i, (pred, prob) in enumerate(zip(predictions, probabilities)):\n",
        "        risk_level = \"High Risk\" if pred == 1 else \"Low Risk\"\n",
        "        risk_probability = prob[1]  # Probability of being high risk\n",
        "        print(f\"\\nApplication {i+1}:\")\n",
        "        print(f\"Risk Level: {risk_level}\")\n",
        "        print(f\"Probability of High Risk: {risk_probability:.2%}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CY5vvDG-gnHD",
        "outputId": "c4685bb8-1075-4ad5-b505-86e13168c65e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model Performance Metrics:\n",
            "Training Accuracy: 1.00\n",
            "Testing Accuracy: 0.93\n",
            "\n",
            "Top 10 Most Important Risk Factors:\n",
            "               feature  importance\n",
            "4               smoker    0.567449\n",
            "2                  bmi    0.148945\n",
            "0                  age    0.111245\n",
            "3             children    0.048266\n",
            "1                  sex    0.021038\n",
            "16    region_southeast    0.012725\n",
            "14    region_northeast    0.012556\n",
            "15    region_northwest    0.009838\n",
            "13  bmi_category_obese    0.009343\n",
            "5       age_group_0-25    0.009215\n",
            "\n",
            "Risk Predictions for New Applications:\n",
            "\n",
            "Application 1:\n",
            "Risk Level: Low Risk\n",
            "Probability of High Risk: 2.00%\n",
            "\n",
            "Application 2:\n",
            "Risk Level: High Risk\n",
            "Probability of High Risk: 98.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_nGJrG-1gm-l"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}